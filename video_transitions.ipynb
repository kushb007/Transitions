{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n"
     ]
    }
   ],
   "source": [
    "print(\"check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\kushb\\anaconda3\\envs\\tf\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy in c:\\users\\kushb\\anaconda3\\envs\\tf\\lib\\site-packages (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\kushb\\anaconda3\\envs\\tf\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\kushb\\anaconda3\\envs\\tf\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\kushb\\anaconda3\\envs\\tf\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python numpy gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting optical flows for .\\curry23.mp4...\n",
      "Extracting optical flows for .\\grant23.mp4...\n",
      "Extracting optical flows for .\\green23.mp4...\n",
      "Extracting optical flows for .\\jokerfloats.mp4...\n",
      "Extracting optical flows for .\\murray22.mp4...\n",
      "Extracting optical flows for .\\thetruth.mp4...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def extract_optical_flows(directory):\n",
    "    optical_flows = {}\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".mp4\"):\n",
    "            video_path = os.path.join(directory, file)\n",
    "            print(f\"Extracting optical flows for {video_path}...\")\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            ret, frame1 = cap.read()\n",
    "            prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "            hsv = np.zeros_like(frame1)\n",
    "            hsv[..., 1] = 255\n",
    "\n",
    "            flows = []\n",
    "            frame_idx = 0\n",
    "            while True:\n",
    "                ret, frame2 = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "                flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "                flows.append(flow)\n",
    "                \n",
    "                # Save the flow to a file\n",
    "                flow_filename = f\"{os.path.splitext(file)[0]}_flow_{frame_idx}.npy\"\n",
    "                np.save(os.path.join(directory, flow_filename), flow)\n",
    "                \n",
    "                prvs = next\n",
    "                frame_idx += 1\n",
    "\n",
    "            cap.release()\n",
    "            #optical_flows[file] = flows\n",
    "\n",
    "    return optical_flows\n",
    "\n",
    "# Extract optical flows for each mp4 in the directory\n",
    "optical_flows = extract_optical_flows(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def load_optical_flows(directory):\n",
    "    flow_files = glob.glob(os.path.join(directory, \"*_flow_*.npy\"))\n",
    "    flows = {}\n",
    "    for file in flow_files:\n",
    "        video_name = os.path.basename(file).split('_flow_')[0]\n",
    "        frame_idx = int(os.path.basename(file).split('_flow_')[1].split('.npy')[0])\n",
    "        if video_name not in flows:\n",
    "            flows[video_name] = []\n",
    "        flows[video_name].append((frame_idx, np.load(file)))\n",
    "    return flows\n",
    "\n",
    "def find_most_similar_flows(flows):\n",
    "    min_diff = float('inf')\n",
    "    best_pair = None\n",
    "    for video1, frames1 in flows.items():\n",
    "        for video2, frames2 in flows.items():\n",
    "            if video1 != video2:\n",
    "                for idx1, flow1 in frames1:\n",
    "                    for idx2, flow2 in frames2:\n",
    "                        diff = np.sum((flow1 - flow2) ** 2)\n",
    "                        if diff < min_diff:\n",
    "                            min_diff = diff\n",
    "                            best_pair = (video1, idx1, video2, idx2)\n",
    "    return best_pair\n",
    "\n",
    "def create_transition_video(video1_path, video2_path, idx1, idx2, output_path):\n",
    "    cap1 = cv2.VideoCapture(video1_path)\n",
    "    cap2 = cv2.VideoCapture(video2_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap1.get(3)), int(cap1.get(4))))\n",
    "\n",
    "    for i in range(idx1):\n",
    "        ret, frame = cap1.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        out.write(frame)\n",
    "\n",
    "    for i in range(idx2, int(cap2.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "        ret, frame = cap2.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        out.write(frame)\n",
    "\n",
    "    cap1.release()\n",
    "    cap2.release()\n",
    "    out.release()\n",
    "\n",
    "# Load optical flows from .npy files\n",
    "flows = load_optical_flows(\".\")\n",
    "\n",
    "# Find the most similar optical flows\n",
    "video1, idx1, video2, idx2 = find_most_similar_flows(flows)\n",
    "\n",
    "# Create a transition video\n",
    "create_transition_video(f\"{video1}.mp4\", f\"{video2}.mp4\", idx1, idx2, \"transition_video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def play_video():\n",
    "    return \"transition_video.mp4\"\n",
    "\n",
    "iface = gr.Interface(fn=play_video, inputs=[], outputs=gr.Video())\n",
    "\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
